{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/teacher/.local/lib/python3.5/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['stack']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import torch\n",
    "import numpy\n",
    "import sklearn.datasets\n",
    "import torchvision.datasets\n",
    "import os\n",
    "from scipy.misc import imresize as imgresize\n",
    "from pycocotools import coco\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dest = \"../../val2017\"\n",
    "target_dest = \"../../annotations/instances_val2017_categories.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json \n",
    "\n",
    "# with open(\"../../annotations/instances_val2017.json\") as rfile, open(\"../../annotations/instances_val2017_categories.json\", 'w') as wfile:\n",
    "#     data = json.load(rfile)\n",
    "    \n",
    "#     new_categories = list(set(list(x[\"category_id\"] for x in data[\"annotations\"])))\n",
    "#     def change_category(ann):\n",
    "#         ann[\"category_id\"] = new_categories.index(ann[\"category_id\"])\n",
    "#         return ann\n",
    "    \n",
    "#     data[\"annotations\"] = list(map(change_category, data[\"annotations\"]))\n",
    "#     json.dump(data, wfile)\n",
    "   \n",
    "# with open(\"../../annotations/instances_train2017.json\") as rfile, open(\"../../annotations/instances_train2017_categories.json\", 'w') as wfile:\n",
    "#     data = json.load(rfile)\n",
    "    \n",
    "#     new_categories = list(set(list(x[\"category_id\"] for x in data[\"annotations\"])))\n",
    "#     def change_category(ann):\n",
    "#         ann[\"category_id\"] = new_categories.index(ann[\"category_id\"])\n",
    "#         return ann\n",
    "    \n",
    "#     data[\"annotations\"] = list(map(change_category, data[\"annotations\"]))\n",
    "#     json.dump(data, wfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.87s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "COCO = coco.COCO(target_dest)\n",
    "category_ids = 80\n",
    "people_category = 0\n",
    "size = (32, 32)\n",
    "def toResizedTensor(np_image):\n",
    "    np_image = (imgresize(np_image, size, 'bilinear') > 0).astype(int)\n",
    "    return torch.from_numpy(np_image).float().unsqueeze(0)\n",
    "\n",
    "def toMask(x):\n",
    "    masks = torch.zeros(80, 1, *size)\n",
    "    for ann in x:\n",
    "        category = ann[\"category_id\"]\n",
    "        mask = COCO.annToMask(ann)\n",
    "        mask = toResizedTensor(mask)\n",
    "        masks[category] += mask\n",
    "    return masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.Resize(size), #реобразует картинку к указанному размеру\n",
    "         torchvision.transforms.ToTensor()                   # Переводит объект \"картинка\" к torch.Tensor\n",
    "    ])\n",
    "\n",
    "train_transforms = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.Lambda(toMask),      \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.67s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "dataset = torchvision.datasets.CocoDetection(train_dest, target_dest, \n",
    "                                             transform=transforms, target_transform=train_transforms)\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    "    batch_size=1,\n",
    "    num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(dataset[3][0].numpy().swapaxes(0,1).swapaxes(1,2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNetConvBlock(torch.nn.Module):\n",
    "    def __init__(self, in_layers, out_layers, kernel_size=3, padding=1, activation=torch.nn.ReLU, pooling=True):\n",
    "        super(UNetConvBlock, self).__init__()\n",
    "        self.conv = torch.nn.Conv2d(in_layers, out_layers, kernel_size, padding=padding)\n",
    "        self.conv2 = torch.nn.Conv2d(out_layers, out_layers, kernel_size, padding=padding)\n",
    "        self.pooling = pooling\n",
    "        self.pool = torch.nn.MaxPool2d(2)\n",
    "        self.activation = activation()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.activation(self.conv(x))\n",
    "        out = self.activation(self.conv2(out))\n",
    "        if (self.pooling):\n",
    "            out = self.pool(out)\n",
    "        return out     \n",
    "    \n",
    "class UNetUpConvBlock(torch.nn.Module):\n",
    "    def __init__(self, in_layers, kernel_size=3, padding=1, activation=torch.nn.ReLU):\n",
    "        super(UNetUpConvBlock, self).__init__()\n",
    "        self.upconv = torch.nn.Conv2d(in_layers, 4*in_layers, 1)\n",
    "        self.transpose = torch.nn.ConvTranspose2d(4*in_layers, in_layers, 2, stride=2)\n",
    "        self.conv = UNetConvBlock(in_layers, in_layers, pooling=False)  \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.upconv(x)\n",
    "        out = self.transpose(out)\n",
    "        out = self.conv(out)\n",
    "        return out    \n",
    "\n",
    "def stack(old, new):\n",
    "    return torch.cat([old, new], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "        \n",
    "        self.conv1 = UNetConvBlock(3, 16)\n",
    "        self.conv2 = UNetConvBlock(16, 32)\n",
    "        self.conv3 = UNetConvBlock(32, 64)\n",
    "\n",
    "        self.upconv3 = UNetUpConvBlock(64) \n",
    "        self.upconv2 = UNetUpConvBlock(96)  # stack with conv2 64 + 32\n",
    "        self.upconv1 = UNetUpConvBlock(112) # stack with conv1 96 + 16\n",
    "        \n",
    "        self.fullconv = torch.nn.Conv2d(115, 80, 1) # with initial 112 + 3\n",
    "        self.pred = torch.nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        initial = x.clone()\n",
    "        \n",
    "        c1 = self.conv1(x)\n",
    "        c2 = self.conv2(c1)          \n",
    "        x = self.conv3(c2)\n",
    "        \n",
    "        x = self.upconv3(x)\n",
    "        \n",
    "        x = stack(c2, x)\n",
    "        x = self.upconv2(x)\n",
    "        \n",
    "        x = stack(c1, x)\n",
    "        x = self.upconv1(x)\n",
    "        \n",
    "        x = stack(initial, x)\n",
    "        x = self.fullconv(x)  \n",
    "        x = self.pred(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = UNet().to(device)\n",
    "\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters())\n",
    "\n",
    "# if os.path.exists(\"state_dict.wght\"):\n",
    "#     net.load_state_dict(torch.load(\"state_dict.wght\"))\n",
    "\n",
    "def intersection_over_union(pred, target):\n",
    "    i, u = 0, 0\n",
    "    for pred_l, target_l in zip(pred, target):\n",
    "        i += (pred_l * target_l > 0).sum().item()\n",
    "        u += (pred_l + target_l > 0).sum().item()\n",
    "    return i / u\n",
    "\n",
    "metric = intersection_over_union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 started\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (2) : out of memory at /pytorch/aten/src/THC/THCTensorCopy.cu:204",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-0f892d216727>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mbatch_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mbatch_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-cb3a8df9d149>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0minitial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (2) : out of memory at /pytorch/aten/src/THC/THCTensorCopy.cu:204"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    print(\"Epoch {} started\".format(epoch))\n",
    "    order = random.permutation(len(dataset.ids))\n",
    "    net.train()\n",
    "    for i, (data, target) in enumerate(data_loader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        batch_features = data.to(device)\n",
    "        batch_labels = target.to(device)\n",
    "        \n",
    "        batch_preds = net.forward(batch_features)\n",
    "\n",
    "        loss = criterion(batch_preds, batch_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i % 50 == 0:\n",
    "            print(\"Batch {} loss {}, \".format(i, loss.item()), end=\"\")\n",
    "            print(\"intersection over union: {}\".format(metric(batch_preds, batch_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showimgs(data_loader, net, batches=1):\n",
    "    for i, (data, target) in enumerate(data_loader):\n",
    "        pred = net.forward(data.to(device))\n",
    "        for img_data, border_data, pred_data in zip(data, target, pred):\n",
    "            fig, (img, border, prediction) = plt.subplots(1, 3)\n",
    "            img.imshow(img_data.numpy().swapaxes(0,1).swapaxes(1,2))\n",
    "            border.imshow(border_data.numpy().squeeze(0))\n",
    "            prediction.imshow(pred_data.cpu().data.numpy().squeeze(0))\n",
    "            plt.show()\n",
    "        if (i == batches):\n",
    "            break\n",
    "        \n",
    "        \n",
    "def showpred(pred):\n",
    "    for i in pred:\n",
    "        plt.imshow(i.numpy().squeeze(0))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showimgs(data_loader, net, batches=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(net.state_dict(), \"state_dict.wght\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
