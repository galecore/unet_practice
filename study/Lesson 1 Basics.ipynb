{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T19:49:23.184885Z",
     "start_time": "2018-07-01T19:49:23.178066Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T19:49:23.565086Z",
     "start_time": "2018-07-01T19:49:23.543795Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.,  1.,  1.],\n",
      "         [ 1.,  1.,  1.],\n",
      "         [ 1.,  1.,  1.],\n",
      "         [ 1.,  1.,  1.]],\n",
      "\n",
      "        [[ 1.,  1.,  1.],\n",
      "         [ 1.,  1.,  1.],\n",
      "         [ 1.,  1.,  1.],\n",
      "         [ 1.,  1.,  1.]],\n",
      "\n",
      "        [[ 1.,  1.,  1.],\n",
      "         [ 1.,  1.,  1.],\n",
      "         [ 1.,  1.,  1.],\n",
      "         [ 1.,  1.,  1.]]])\n",
      "tensor([[  1.,   2.,   3.,   4.],\n",
      "        [  5.,   6.,   7.,   8.],\n",
      "        [  9.,  10.,  11.,  12.]]) <- tensor\n",
      "\n",
      "torch.Size([3, 4]) <- tensor size\n",
      "\n",
      "3 <- dimension size\n",
      "\n",
      "tensor([[  6.,   7.],\n",
      "        [ 10.,  11.]]) <- slicing support\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Создаем тензор\n",
    "x = torch.rand([3, 4])\n",
    "x = torch.zeros([3, 4])\n",
    "x = torch.ones([3, 4, 3])\n",
    "\n",
    "print(x)\n",
    "#x = torch.eye(3, 4)\n",
    "\n",
    "x = torch.tensor(\n",
    "[[1,  2,  3,  4],\n",
    " [5,  6,  7,  8],\n",
    " [9, 10, 11, 12]], dtype=torch.float32)\n",
    "\n",
    "print(x, '<- tensor\\n')\n",
    "print(x.size(), '<- tensor size\\n')\n",
    "print(x.size(0), '<- dimension size\\n')\n",
    "print(x[1:, 1:3], '<- slicing support\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T19:50:09.548172Z",
     "start_time": "2018-07-01T19:50:09.533465Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  1.,   2.,   3.,   4.],\n",
      "        [  1.,   1.,   1.,   1.],\n",
      "        [  9.,  10.,  11.,  12.]]) \n",
      " tensor([[  1.,   2.,   3.,   4.],\n",
      "        [  1.,   1.,   1.,   1.],\n",
      "        [  9.,  10.,  11.,  12.]]) <- shallow copy\n",
      "\n",
      "tensor([[  1.,   2.,   3.,   4.],\n",
      "        [  1.,   1.,   1.,   1.],\n",
      "        [  9.,  10.,  11.,  12.]]) \n",
      " tensor([[  1.,   2.,   3.,   4.],\n",
      "        [  2.,   2.,   2.,   2.],\n",
      "        [  9.,  10.,  11.,  12.]]) <- deep copy\n"
     ]
    }
   ],
   "source": [
    "# Копирование (по ссылке и глубокое)\n",
    "y = x\n",
    "\n",
    "y[1, :] = 1\n",
    "print(x, '\\n', y, '<- shallow copy\\n')\n",
    "\n",
    "y = x.clone()\n",
    "y[1, :] = 2\n",
    "print(x, '\\n', y, '<- deep copy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T19:50:55.156964Z",
     "start_time": "2018-07-01T19:50:55.142559Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  2.,   4.,   6.,   8.],\n",
      "        [  3.,   3.,   3.,   3.],\n",
      "        [ 18.,  20.,  22.,  24.]]) tensor([[   1.,    4.,    9.,   16.],\n",
      "        [   2.,    2.,    2.,    2.],\n",
      "        [  81.,  100.,  121.,  144.]]) tensor([[ 1.0000,  1.0000,  1.0000,  1.0000],\n",
      "        [ 0.5000,  0.5000,  0.5000,  0.5000],\n",
      "        [ 1.0000,  1.0000,  1.0000,  1.0000]]) tensor([[ 0.,  0.,  0.,  0.],\n",
      "        [-1., -1., -1., -1.],\n",
      "        [ 0.,  0.,  0.,  0.]])\n",
      "tensor([[ 0.,  0.,  0.,  0.],\n",
      "        [ 1.,  1.,  1.,  1.],\n",
      "        [ 0.,  0.,  0.,  0.]]) tensor([[   1.,    4.,    9.,   16.],\n",
      "        [   1.,    1.,    1.,    1.],\n",
      "        [  81.,  100.,  121.,  144.]]) tensor([[ 1.0000e+00,  4.0000e+00,  2.7000e+01,  2.5600e+02],\n",
      "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
      "        [ 3.8742e+08,  1.0000e+10,  2.8531e+11,  8.9161e+12]]) <- basic math\n"
     ]
    }
   ],
   "source": [
    "# Математические операции (стандартные поэлементные)\n",
    "print(x + y, x * y, x / y, x - y,)\n",
    "print(x % y, x**2, x**y, '<- basic math')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T19:50:55.324289Z",
     "start_time": "2018-07-01T19:50:55.311976Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.7183e+00,  7.3891e+00,  2.0086e+01,  5.4598e+01],\n",
      "        [ 2.7183e+00,  2.7183e+00,  2.7183e+00,  2.7183e+00],\n",
      "        [ 8.1031e+03,  2.2026e+04,  5.9874e+04,  1.6275e+05]])\n",
      "tensor([[ 0.0000,  0.6931,  1.0986,  1.3863],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 2.1972,  2.3026,  2.3979,  2.4849]])\n",
      "tensor([[ 0.8415,  0.9093,  0.1411, -0.7568],\n",
      "        [ 0.8415,  0.8415,  0.8415,  0.8415],\n",
      "        [ 0.4121, -0.5440, -1.0000, -0.5366]])\n"
     ]
    }
   ],
   "source": [
    "# Более сложные операции\n",
    "print(torch.exp(x))\n",
    "print(torch.log(x))\n",
    "print(torch.sin(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T19:50:55.451918Z",
     "start_time": "2018-07-01T19:50:55.439867Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  4.,   9.,  10.,  11.,  12.])\n",
      "tensor([[ 0,  0,  0,  1],\n",
      "        [ 0,  0,  0,  0],\n",
      "        [ 1,  1,  1,  1]], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "# Логические операции\n",
    "y = x[x > 3]\n",
    "print(y)\n",
    "y = (x > 3)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T19:50:55.883799Z",
     "start_time": "2018-07-01T19:50:55.869374Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  1.,   2.,   3.,   4.],\n",
      "        [  1.,   1.,   1.,   1.],\n",
      "        [  9.,  10.,  11.,  12.]])\n",
      "tensor([[  1.,   2.,   3.,   4.],\n",
      "        [  1.,   1.,   1.,   1.],\n",
      "        [  9.,  10.,  11.,  12.]], dtype=torch.float64)\n",
      "tensor([[  1,   2,   3,   4],\n",
      "        [  1,   1,   1,   1],\n",
      "        [  9,  10,  11,  12]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# Переопределение типа\n",
    "x = x.float()\n",
    "print(x)\n",
    "x = x.double()\n",
    "print(x)\n",
    "x = x.int()\n",
    "print(x)\n",
    "x = x.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T19:50:56.556514Z",
     "start_time": "2018-07-01T19:50:56.537230Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3 4]\n",
      " [4 3 2 1]]\n",
      "tensor([[ 1,  2,  3,  4],\n",
      "        [ 4,  3,  2,  1]])\n",
      "[[1 2 3 4]\n",
      " [4 3 2 1]]\n",
      "tensor([[ 1.,  2.,  3.,  4.],\n",
      "        [ 4.,  3.,  2.,  1.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Взаимодействие с Numpy\n",
    "x = numpy.array([[1, 2, 3, 4], [4, 3, 2, 1]])\n",
    "print(x)\n",
    "x = torch.from_numpy(x)\n",
    "print(x)\n",
    "x = x.numpy()\n",
    "print(x)\n",
    "x = torch.from_numpy(x).float().int().double()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T20:46:30.246398Z",
     "start_time": "2018-07-01T20:46:30.239804Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0 is avaliable\n",
      "tensor([[ 1.,  2.,  3.,  4.],\n",
      "        [ 4.,  3.,  2.,  1.]], dtype=torch.float64, device='cuda:0') <- CUDA Tensor!\n",
      "tensor([[ 1.,  2.,  3.,  4.],\n",
      "        [ 4.,  3.,  2.,  1.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Перемещение на GPU\n",
    "import time\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device, 'is avaliable')\n",
    "x_cuda = x.to(device)\n",
    "print(x_cuda, '<- CUDA Tensor!')\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T20:45:50.719046Z",
     "start_time": "2018-07-01T20:45:50.711778Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 127 µs, sys: 41 µs, total: 168 µs\n",
      "Wall time: 224 µs\n"
     ]
    }
   ],
   "source": [
    "# CPU time\n",
    "%time y = (x - x + x*10.0) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T20:46:33.594104Z",
     "start_time": "2018-07-01T20:46:33.590407Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 659 µs, sys: 0 ns, total: 659 µs\n",
      "Wall time: 403 µs\n"
     ]
    }
   ],
   "source": [
    "# GPU time\n",
    "%time y_cuda = (x_cuda - x_cuda + x_cuda * 10.0) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T20:03:38.164937Z",
     "start_time": "2018-07-01T20:03:38.154058Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  2,   4,   6,   8],\n",
      "        [ 10,  12,  14,  16],\n",
      "        [ 18,  20,  22,  24]]) <- gradient\n"
     ]
    }
   ],
   "source": [
    "# Автоматическое (символьное) дифференциирование (обратное распространение градиента) (случай скаляра)\n",
    "import torch.autograd\n",
    "\n",
    "x = torch.tensor(\n",
    "    [[1,  2,  3,  4],\n",
    "     [5,  6,  7,  8],\n",
    "     [9, 10, 11, 12]], requires_grad=True)\n",
    "\n",
    "formula = (x ** 2).sum().median()\n",
    "formula.backward()\n",
    "\n",
    "print(x.grad, '<- gradient')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T20:30:40.079846Z",
     "start_time": "2018-07-01T20:30:40.069890Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MedianBackward0 object at 0x7f0b104738d0>\n",
      "<SumBackward0 object at 0x7f0aa54097f0>\n",
      "<PowBackward0 object at 0x7f0b104738d0>\n",
      "<AccumulateGrad object at 0x7f0aa5409828>\n"
     ]
    }
   ],
   "source": [
    "# Как тензор хранит свою историю\n",
    "print(formula.grad_fn)\n",
    "print(formula.grad_fn.next_functions[0][0])\n",
    "print(formula.grad_fn.next_functions[0][0].next_functions[0][0])\n",
    "print(formula.grad_fn.next_functions[0][0].next_functions[0][0].next_functions[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1\n",
    "Написать и вычислить бинарную кросс-энтопию для векторов target и probs при помощи средств pytorch.\n",
    "Бинарная кросс-энтропия вычисляется:\n",
    "\n",
    "$$BCE(t, p) = - \\sum_i t_i \\log(p_i) + (1 - t_i) \\log(1 - p_i)$$\n",
    "\n",
    "target = (0, 0, 0, 0, 1, 1, 1, 1)\n",
    "probs = (0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8)\n",
    "\n",
    "Какой из элементов суммы дает наибольший вклад в функцию потерь?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.9798)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = torch.tensor([0, 0, 0, 0, 1, 1, 1, 1], requires_grad=True) \n",
    "probs = torch.tensor([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8], requires_grad=True)\n",
    "\n",
    "def bce(t, p):\n",
    "    return - ((torch.log(p[t == 1]).sum() + (torch.log(1 - p[t == 0]).sum())))\n",
    "bce(target, probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 2\n",
    "\n",
    "Логистическая регрессия минимизирует функцию бинарной кросс-энтропии (BCE), предполагая, что\n",
    "$$p_i = \\sigma (< w_i, x_i >)$$\n",
    "где $w_i$ -- веса свойств объектов, $x_i$ -- свойства объектов. Пусть $\\vec{x} = (1, x_1, x_2)$. Подставить вероятности в выражение $BCE$ и найти производную $BCE$ по весам.\n",
    "Вычислить производную в случае двух объектов (любым способом, можно посчитать руками, можно написать скрипт):\n",
    "\n",
    "$t = 1, x = (1, 1, 1)$\n",
    "\n",
    "$t = 0, x = (1, 0, 1)$\n",
    "\n",
    "В точке w = (0, 0, 0).\n",
    "\n",
    "Совпадает ли результат явного вычисления с результатом работы функции backward?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.5000,  0.5000])\n",
      "tensor(1.3863) tensor([ 0.0000, -0.5000,  0.0000])\n"
     ]
    }
   ],
   "source": [
    "def sigmoid(w, x):\n",
    "    scalar = -x @ w.transpose(-1,0)\n",
    "    return 1 / (1 + torch.exp(scalar) + 1e-10)\n",
    "\n",
    "w = torch.tensor([0,0,0], requires_grad=True, dtype=torch.float32)\n",
    "x = torch.tensor([[1,1,1],[1,0,1]], dtype=torch.float32)\n",
    "\n",
    "\n",
    "probs = sigmoid(w,x)\n",
    "print(probs)\n",
    "f = bce(torch.tensor([1,0]), probs)\n",
    "f.backward()\n",
    "print(f, w.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3\n",
    "\n",
    "Средствами pytorch реализовать алгоритм градиентного спуска.\n",
    "\n",
    "При помощи этого алгоритма найти минимум функций:\n",
    "$x^2 + y^2$ с начальным приближением $x_0 = 10, y_0 = 5$, \n",
    "\n",
    "$0.5 \\log x + 0.5 \\log (1 - x)$ с начальным приближением $x_0 = 0.9$, \n",
    "\n",
    "$x^2 + 10 y^2 + 2xy$, с начальным приближением $x_0 = 10.0, y_0 = 10.0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GD(f, x, y, alpha=torch.tensor(1e-1)):\n",
    "    for i in range(30000):\n",
    "        f.backward(retain_graph=True)\n",
    "        x.data.sub_(alpha * x.grad)\n",
    "        y.data.sub_(alpha * y.grad)\n",
    "        x.grad = torch.tensor(0, dtype=torch.float32)\n",
    "        y.grad = torch.tensor(0, dtype=torch.float32)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(1.00000e-45 *\n",
      "       2.8026), tensor(1.00000e-45 *\n",
      "       2.8026))\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(10, requires_grad=True, dtype=torch.float32)\n",
    "y = torch.tensor(5, requires_grad=True, dtype=torch.float32)\n",
    "\n",
    "f = x**2 + y**2\n",
    "\n",
    "print(GD(f, x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(15000.1553), tensor(1.00000e-45 *\n",
      "       2.8026))\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(0.9, requires_grad=True, dtype=torch.float32)\n",
    "\n",
    "f = 0.5*torch.log(x) + 0.5*torch.log(1-x)\n",
    "\n",
    "print(GD(f, x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(2.2222), tensor(10.))\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(10, requires_grad=True, dtype=torch.float32)\n",
    "y = torch.tensor(10, requires_grad=True, dtype=torch.float32)\n",
    "\n",
    "f = x**2 + 10*y**2 + 2*x*y\n",
    "\n",
    "print(GD(f, x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 4\n",
    "\n",
    "\n",
    "При помощи алгоритма градиентного спуска оптимизировать вектор probs при фиксированном векторе target из задания 1.\n",
    "Рассмотреть два варианта решения задачи: \n",
    "\n",
    "1) при помощи CPU \n",
    "\n",
    "2) при помощи GPU\n",
    "\n",
    "Получилось ли ускорить процесс при помощи GPU? Обсудить, почему."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(w, x):\n",
    "    scalar = -x @ w.transpose(-1,0)\n",
    "    return 1 / (1 + torch.exp(scalar) + 1e-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GD(f, x, alpha=torch.tensor(0.005, dtype=torch.float32, device=device)):\n",
    "    for i in range(10000):\n",
    "        f.backward(retain_graph=True)\n",
    "        x.data.sub_(alpha * x.grad.data)\n",
    "        x.grad = torch.zeros(x.size(), dtype=torch.float32, device=device)\n",
    "    return x\n",
    "\n",
    "def bce(t, p):\n",
    "    return - ((torch.log(p[t == 1]).sum() + (torch.log(1 - p[t == 0]).sum())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "О градиентном спуске:\n",
    "https://ru.wikipedia.org/wiki/%D0%93%D1%80%D0%B0%D0%B4%D0%B8%D0%B5%D0%BD%D1%82%D0%BD%D1%8B%D0%B9_%D1%81%D0%BF%D1%83%D1%81%D0%BA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -55.4509,  -62.2940,  -71.1196,  -82.9351,  100.5031,   83.9349,\n",
      "          72.1194,   63.2937], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "target = torch.tensor([0, 0, 0, 0, 1, 1, 1, 1], dtype=torch.float32, device=device) \n",
    "probs = torch.tensor([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8], dtype=torch.float32, requires_grad=True, device=device)\n",
    "\n",
    "f = bce(target, probs)\n",
    "print(GD(f, probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
